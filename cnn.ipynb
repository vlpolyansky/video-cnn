{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "def randfloat(a, b):\n",
    "    return rand.random() * (b - a) + a\n",
    "\n",
    "def my_print(s):\n",
    "    sys.stdout.write(s)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"./data/synthetic/\"\n",
    "save_file_path = \"./save/model.ckpt\"\n",
    "logs_dir = \"./logs\"\n",
    "logs_dir_2 = \"./logs2\"\n",
    "\n",
    "create_dir(\"./save\")\n",
    "create_dir(logs_dir)\n",
    "create_dir(logs_dir_2)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_SIZE = 64\n",
    "\n",
    "_debug_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _create_label_producers():\n",
    "    labels_fname = os.path.join(data_dir, \"labels.csv\")\n",
    "    labels = pd.read_csv(labels_fname, header=None)\n",
    "    lines = [os.path.join(data_dir, \"input\", str(l[0]) + \".png\") + \" \" + str((l[1] + 1) / 2) for l in labels.values]\n",
    "    cnt = len(lines)\n",
    "    p = 0.9\n",
    "    train_cnt = int(cnt * p)\n",
    "    print \"Total: %i images, train: %i\" % (cnt, train_cnt)\n",
    "    train_lines = lines[:train_cnt]\n",
    "    test_lines = lines[train_cnt:]\n",
    "    return tf.train.string_input_producer(train_lines), tf.train.string_input_producer(test_lines)\n",
    "\n",
    "def _read_image_and_label(path_label_line):\n",
    "    with tf.name_scope(\"read_image_and_label\"):\n",
    "        path, label_str = tf.decode_csv(path_label_line, [[\"\"], [\"\"]], field_delim=\" \")\n",
    "        label = tf.cast(tf.string_to_number(label_str, out_type=tf.int32), tf.int64)\n",
    "        file_content = tf.read_file(path)\n",
    "        image3c = tf.image.decode_png(file_content)\n",
    "        image1, image2 = tf.split(1, 2, image3c)\n",
    "        image1 = tf.cast(image1, tf.float32)\n",
    "        image2 = tf.cast(image2, tf.float32)\n",
    "        image1.set_shape((IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "        image2.set_shape((IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    return image1, image2, label\n",
    "\n",
    "def _generate_batch(image1, image2, label, batch_size, min_after_dequeue=20000):\n",
    "    with tf.name_scope(\"generate_batch\"):\n",
    "        images1, images2, labels = tf.train.shuffle_batch([image1, image2, label], batch_size=batch_size, \n",
    "                                                capacity=min_after_dequeue + batch_size * 4, \n",
    "                                                min_after_dequeue=min_after_dequeue,\n",
    "                                                num_threads=5)\n",
    "    return images1, images2, tf.reshape(labels, [batch_size])\n",
    "    \n",
    "def get_data_batch():\n",
    "    train_queue, test_queue = _create_label_producers()\n",
    "    image1_train, image2_train, label_train = _read_image_and_label(train_queue.dequeue())\n",
    "    image1_test, image2_test, label_test = _read_image_and_label(test_queue.dequeue())\n",
    "    images1_train, images2_train, labels_train = _generate_batch(image1_train, image2_train, \n",
    "                                                                 label_train, BATCH_SIZE)\n",
    "    images1_test, images2_test, labels_test = _generate_batch(image1_test, image2_test, \n",
    "                                                              label_test, BATCH_SIZE,\n",
    "                                                              min_after_dequeue=BATCH_SIZE)\n",
    "    return images1_train, images2_train, labels_train, images1_test, images2_test, labels_test\n",
    "\n",
    "def dense_to_one_hot(label_batch, num_labels=2):\n",
    "    with tf.name_scope(\"one_hot_encoder\"):\n",
    "        sparse_labels = tf.cast(tf.reshape(label_batch, [-1, 1]), tf.int32)\n",
    "        derived_size = tf.shape(sparse_labels)[0]\n",
    "        indices = tf.reshape(tf.range(0, derived_size, 1), [-1, 1])\n",
    "        concated = tf.concat(1, [indices, sparse_labels])\n",
    "        outshape = tf.concat(0, [tf.reshape(derived_size, [1]), tf.reshape(num_labels, [1])])\n",
    "        labels = tf.sparse_to_dense(concated, outshape, 1.0, 0.0)\n",
    "        labels = tf.cast(labels, tf.float32)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _activation_summary(x):\n",
    "    tensor_name = x.op.name\n",
    "    tf.histogram_summary(tensor_name + '/activations', x)\n",
    "    tf.scalar_summary(tensor_name + '/sparsity', tf.nn.zero_fraction(x))\n",
    "\n",
    "\n",
    "def _create_conv(layer, kernel_shape, kernel_stddev=1e-3, activation=tf.nn.relu, name=\"conv\", trainable=True):\n",
    "    with tf.name_scope(name):\n",
    "        kernel = tf.Variable(tf.truncated_normal(kernel_shape, stddev=kernel_stddev), name=\"kernel\", \n",
    "                             trainable=trainable)\n",
    "        tf.add_to_collection('main', kernel)\n",
    "        conv = tf.nn.conv2d(layer, kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[kernel_shape[3]]), name=\"biases\", trainable=trainable)\n",
    "        tf.add_to_collection('main', biases)\n",
    "        biased = tf.nn.bias_add(conv, biases)\n",
    "        conv_relu = activation(biased)\n",
    "        _activation_summary(conv_relu)\n",
    "\n",
    "    return conv_relu\n",
    "    \n",
    "def _create_pool(layer, kernel_width, stride=1, name=\"pool\"):\n",
    "    with tf.name_scope(name):\n",
    "        pool = tf.nn.max_pool(layer, ksize=[1, kernel_width, kernel_width, 1], strides=[1, stride, stride, 1],\n",
    "                             padding='SAME')\n",
    "    return pool\n",
    "\n",
    "def _create_norm(layer, name=\"norm\"):\n",
    "    with tf.name_scope(name):\n",
    "        norm = tf.nn.lrn(layer, alpha=0.001 / 9.0, beta=0.75)\n",
    "    return norm\n",
    "\n",
    "def _create_full(layer, result_size, weights_stddev=.04, activation=tf.nn.relu, name=\"full\", trainable=True):\n",
    "    with tf.name_scope(name):\n",
    "        layer_size = 1\n",
    "        for k in layer.get_shape()[1:].as_list():\n",
    "            layer_size *= k\n",
    "        reshaped = tf.reshape(layer, [BATCH_SIZE, layer_size])\n",
    "        weights = tf.Variable(tf.truncated_normal([layer_size, result_size], stddev=weights_stddev), name=\"weights\",\n",
    "                             trainable=trainable)\n",
    "        tf.add_to_collection('main', weights)\n",
    "        biases = tf.Variable(tf.constant(.1, shape=[result_size]), name=\"biases\", trainable=trainable)\n",
    "        tf.add_to_collection('main', biases)\n",
    "        if activation:\n",
    "            biased = tf.add(tf.matmul(reshaped, weights), biases)\n",
    "            result = activation(biased)\n",
    "        else:\n",
    "            result = tf.add(tf.matmul(reshaped, weights), biases)\n",
    "        \n",
    "        _activation_summary(result)\n",
    "    return result\n",
    "    \n",
    "def build_classifier(images1, images2, trainable=True):\n",
    "    images = tf.concat(3, [images1, images2])\n",
    "    \n",
    "    conv1 = _create_conv(images, [5, 5, 6, 64], name=\"conv1\", trainable=trainable)\n",
    "    pool1 = _create_pool(conv1, 3, 2, name=\"pool1\")\n",
    "    norm1 = _create_norm(pool1, name=\"norm1\")\n",
    "    \n",
    "    conv2 = _create_conv(norm1, [5, 5, 64, 64], name=\"conv2\", trainable=trainable)\n",
    "    pool2 = _create_pool(conv2, 3, 2, name=\"pool2\")\n",
    "    norm2 = _create_norm(pool2, name=\"norm2\")\n",
    "    \n",
    "    conv3 = _create_conv(norm2, [4, 4, 64, 32], name=\"conv3\", trainable=trainable)\n",
    "    pool3 = _create_pool(conv3, 3, 2, name=\"pool3\")\n",
    "#     norm3 = _create_norm(pool3, name=\"norm3\")\n",
    "    \n",
    "    full1 = _create_full(pool3, 256, name=\"full1\", activation=tf.nn.relu, trainable=trainable)\n",
    "    full2 = _create_full(full1, 128, name=\"full2\", activation=tf.nn.relu, trainable=trainable)\n",
    "    full3 = _create_full(full2, 2, name=\"full3\", activation=None, trainable=trainable)\n",
    "    \n",
    "    softmax = tf.nn.softmax(full3, name=\"softmax\")\n",
    "    \n",
    "    return softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_loss(logits, labels):\n",
    "    with tf.name_scope(\"cross_entropy\"):\n",
    "        labels = tf.cast(labels, tf.int64)\n",
    "        dense_labels = dense_to_one_hot(labels)\n",
    "        clipped_logits = tf.clip_by_value(logits, 0.00001, 100.0)\n",
    "        cross_entropy = -dense_labels * tf.log(clipped_logits)\n",
    "#         cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, dense_labels, \n",
    "#                                                                 name='cross_entropy_per_example')\n",
    "        cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "\n",
    "    return cross_entropy_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_train(loss_op, step, init_rate=0.1, decay_steps=8000):\n",
    "\n",
    "    with tf.name_scope(\"train\"):\n",
    "        learning_rate = tf.train.exponential_decay(init_rate, step, decay_steps, 0.1, staircase=True)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        grads = optimizer.compute_gradients(loss_op)\n",
    "\n",
    "        apply_gradient_op = optimizer.apply_gradients(grads, global_step=step)\n",
    "\n",
    "        for var in tf.trainable_variables():\n",
    "            tf.histogram_summary(var.op.name, var)\n",
    "\n",
    "        for grad, var in grads:\n",
    "            if grad:\n",
    "                tf.histogram_summary(var.op.name + '/gradients', grad)\n",
    "\n",
    "    return apply_gradient_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load(saver, sess):\n",
    "    saver.restore(sess, save_file_path)\n",
    "    print \"Model restored.\"\n",
    "    \n",
    "def save(saver, sess):\n",
    "    save_path = saver.save(sess, save_file_path)\n",
    "    print \"Model saved in file: %s\" % save_path\n",
    "\n",
    "def train_classifier(need_load):\n",
    "    global _debug_list\n",
    "    _debug_list = []\n",
    "    N = 50000\n",
    "    \n",
    "    with tf.Graph().as_default() as g: \n",
    "        \n",
    "        step = tf.Variable(0, trainable=False, name=\"step\")\n",
    "        tf.add_to_collection(\"main\", step)\n",
    "    \n",
    "        images1_train, images2_train, labels_train, images1_test, images2_test, labels_test = get_data_batch()\n",
    "        images1_ph = tf.placeholder(tf.float32, [BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3], \"images1\")\n",
    "        images2_ph = tf.placeholder(tf.float32, [BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3], \"images2\")\n",
    "        labels_ph = tf.placeholder(tf.int64, [BATCH_SIZE], \"labels\")\n",
    "        answer_op = build_classifier(images1_ph, images2_ph, trainable=True)\n",
    "        loss_op = build_loss(answer_op, labels_ph)\n",
    "        train_op = build_train(loss_op, step)\n",
    "        correct_prediction = tf.equal(tf.argmax(answer_op, 1), labels_ph)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        accuracy_summary = tf.scalar_summary(\"accuracy\", accuracy)\n",
    "\n",
    "        merged_summaries = tf.merge_all_summaries()\n",
    "\n",
    "        init = tf.initialize_all_variables()\n",
    "\n",
    "        sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "        saver = tf.train.Saver(var_list=tf.get_collection(\"main\"))\n",
    "        coord = tf.train.Coordinator()\n",
    "        writer = tf.train.SummaryWriter(logs_dir, sess.graph_def, flush_secs=30)\n",
    "\n",
    "        sess.run(init)\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "        try:\n",
    "\n",
    "            if need_load:\n",
    "                load(saver, sess)\n",
    "\n",
    "            my_print(\"Starting...\\n\")\n",
    "\n",
    "            for i in xrange(0, N):\n",
    "                if i % 11 == 0:\n",
    "                    im1, im2, lab = sess.run([images1_test, images2_test, labels_test])\n",
    "                    feed = {\n",
    "                        images1_ph : im1,\n",
    "                        images2_ph : im2,\n",
    "                        labels_ph : lab\n",
    "                    }\n",
    "                    result = sess.run([merged_summaries, accuracy, step], feed_dict=feed)\n",
    "                    summary_str = result[0]\n",
    "                    acc = result[1]\n",
    "                    st = result[2]\n",
    "                    writer.add_summary(summary_str, st)\n",
    "                    print(\"Accuracy at step %s: %s\" % (st, acc))\n",
    "                else:\n",
    "                    im1, im2, lab = sess.run([images1_train, images2_train, labels_train])\n",
    "                    feed = {\n",
    "                        images1_ph : im1,\n",
    "                        images2_ph : im2,\n",
    "                        labels_ph : lab\n",
    "                    }\n",
    "                    sess.run(train_op, feed_dict=feed)\n",
    "\n",
    "                if i % 100 == 0:\n",
    "                    save(saver, sess)\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_loss(images1, images2):\n",
    "    return tf.constant(0, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_image():\n",
    "    N = 20000\n",
    "    \n",
    "    with tf.Graph().as_default() as g:\n",
    "        \n",
    "        step = tf.Variable(0, trainable=False, name=\"step_2\")\n",
    "    \n",
    "        _, _, _, images1_test, _, labels_test = get_data_batch()\n",
    "        images1_ph = tf.placeholder(tf.float32, [BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3], \"images1\")\n",
    "#         images2 = tf.Variable(tf.random_uniform([BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3], 0, 1), \"images2\")\n",
    "        images2 = tf.Variable(tf.constant(0, tf.float32, [BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3]), \"images2\")\n",
    "#         images2 = tf.Variable(images1_ph, \"images2\")\n",
    "        tf.image_summary(\"given\", images1_ph)\n",
    "        tf.image_summary(\"generated\", images2)\n",
    "        labels_ph = tf.placeholder(tf.int64, [BATCH_SIZE], \"labels\")\n",
    "        answer_op = build_classifier(images1_ph, images2, trainable=False)\n",
    "        l_loss = build_loss(answer_op, labels_ph)\n",
    "        p_loss = pair_loss(images1_ph, images2)\n",
    "        tf.scalar_summary(\"l_loss\", l_loss)\n",
    "        tf.scalar_summary(\"p_loss\", p_loss)\n",
    "        loss_op = l_loss + p_loss\n",
    "        train_op = build_train(loss_op, step, init_rate=10., decay_steps=5000)\n",
    "        correct_prediction = tf.equal(tf.argmax(answer_op, 1), labels_ph)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        accuracy_summary = tf.scalar_summary(\"accuracy\", accuracy)\n",
    "\n",
    "        merged_summaries = tf.merge_all_summaries()\n",
    "\n",
    "        init = tf.initialize_all_variables()\n",
    "        \n",
    "        sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "        saver = tf.train.Saver(var_list=tf.get_collection(\"main\"))\n",
    "        coord = tf.train.Coordinator()\n",
    "        writer = tf.train.SummaryWriter(logs_dir_2, sess.graph_def, flush_secs=30)\n",
    "\n",
    "        sess.run(init)\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        \n",
    "        \n",
    "        im1, lab = sess.run([images1_test, labels_test])\n",
    "        feed = {\n",
    "            images1_ph : im1,\n",
    "            labels_ph : lab\n",
    "        }\n",
    "        \n",
    "        sess.run(tf.assign(images2, images1_ph), feed_dict=feed)\n",
    "\n",
    "        try:\n",
    "\n",
    "            load(saver, sess)\n",
    "\n",
    "            my_print(\"Starting...\\n\")\n",
    "\n",
    "            for i in xrange(N):\n",
    "                if i % 11 == 0:\n",
    "                    result = sess.run([merged_summaries, accuracy, step], feed_dict=feed)\n",
    "                    summary_str = result[0]\n",
    "                    acc = result[1]\n",
    "                    st = result[2]\n",
    "                    writer.add_summary(summary_str, st)\n",
    "                    print(\"Accuracy at step %s: %s\" % (st, acc))\n",
    "                else:\n",
    "                    sess.run(train_op, feed_dict=feed)\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "train_classifier(need_load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 10000 images, train: 9000\n",
      "Model restored.\n",
      "Starting...\n",
      "Accuracy at step 0: 0.484375\n",
      "Accuracy at step 10: 0.484375\n",
      "Accuracy at step 20: 0.484375\n",
      "Accuracy at step 30: 0.484375\n",
      "Accuracy at step 40: 0.484375\n",
      "Accuracy at step 50: 0.484375\n",
      "Accuracy at step 60: 0.492188\n",
      "Accuracy at step 70: 0.492188\n",
      "Accuracy at step 80: 0.5\n",
      "Accuracy at step 90: 0.507812\n",
      "Accuracy at step 100: 0.523438\n",
      "Accuracy at step 110: 0.53125\n",
      "Accuracy at step 120: 0.539062\n",
      "Accuracy at step 130: 0.539062\n",
      "Accuracy at step 140: 0.539062\n",
      "Accuracy at step 150: 0.5625\n",
      "Accuracy at step 160: 0.5625\n",
      "Accuracy at step 170: 0.578125\n",
      "Accuracy at step 180: 0.585938\n",
      "Accuracy at step 190: 0.59375\n",
      "Accuracy at step 200: 0.609375\n",
      "Accuracy at step 210: 0.632812\n",
      "Accuracy at step 220: 0.632812\n",
      "Accuracy at step 230: 0.632812\n",
      "Accuracy at step 240: 0.640625\n",
      "Accuracy at step 250: 0.640625\n",
      "Accuracy at step 260: 0.648438\n",
      "Accuracy at step 270: 0.65625\n",
      "Accuracy at step 280: 0.65625\n",
      "Accuracy at step 290: 0.65625\n",
      "Accuracy at step 300: 0.65625\n",
      "Accuracy at step 310: 0.65625\n",
      "Accuracy at step 320: 0.671875\n",
      "Accuracy at step 330: 0.679688\n",
      "Accuracy at step 340: 0.679688\n",
      "Accuracy at step 350: 0.679688\n",
      "Accuracy at step 360: 0.679688\n",
      "Accuracy at step 370: 0.6875\n",
      "Accuracy at step 380: 0.6875\n",
      "Accuracy at step 390: 0.6875\n",
      "Accuracy at step 400: 0.695312\n",
      "Accuracy at step 410: 0.703125\n",
      "Accuracy at step 420: 0.710938\n",
      "Accuracy at step 430: 0.71875\n",
      "Accuracy at step 440: 0.71875\n",
      "Accuracy at step 450: 0.71875\n",
      "Accuracy at step 460: 0.734375\n",
      "Accuracy at step 470: 0.734375\n",
      "Accuracy at step 480: 0.742188\n",
      "Accuracy at step 490: 0.75\n",
      "Accuracy at step 500: 0.75\n",
      "Accuracy at step 510: 0.75\n",
      "Accuracy at step 520: 0.75\n",
      "Accuracy at step 530: 0.75\n",
      "Accuracy at step 540: 0.75\n",
      "Accuracy at step 550: 0.75\n",
      "Accuracy at step 560: 0.75\n",
      "Accuracy at step 570: 0.75\n",
      "Accuracy at step 580: 0.75\n",
      "Accuracy at step 590: 0.75\n",
      "Accuracy at step 600: 0.75\n",
      "Accuracy at step 610: 0.757812\n",
      "Accuracy at step 620: 0.757812\n",
      "Accuracy at step 630: 0.757812\n",
      "Accuracy at step 640: 0.757812\n",
      "Accuracy at step 650: 0.757812\n",
      "Accuracy at step 660: 0.757812\n",
      "Accuracy at step 670: 0.757812\n",
      "Accuracy at step 680: 0.757812\n",
      "Accuracy at step 690: 0.757812\n",
      "Accuracy at step 700: 0.757812\n",
      "Accuracy at step 710: 0.765625\n",
      "Accuracy at step 720: 0.765625\n",
      "Accuracy at step 730: 0.765625\n",
      "Accuracy at step 740: 0.765625\n",
      "Accuracy at step 750: 0.773438\n",
      "Accuracy at step 760: 0.773438\n",
      "Accuracy at step 770: 0.773438\n",
      "Accuracy at step 780: 0.773438\n",
      "Accuracy at step 790: 0.773438\n",
      "Accuracy at step 800: 0.773438\n",
      "Accuracy at step 810: 0.773438\n",
      "Accuracy at step 820: 0.773438\n",
      "Accuracy at step 830: 0.773438\n",
      "Accuracy at step 840: 0.773438\n",
      "Accuracy at step 850: 0.773438\n",
      "Accuracy at step 860: 0.773438\n",
      "Accuracy at step 870: 0.773438\n",
      "Accuracy at step 880: 0.773438\n",
      "Accuracy at step 890: 0.773438\n",
      "Accuracy at step 900: 0.773438\n",
      "Accuracy at step 910: 0.773438\n",
      "Accuracy at step 920: 0.773438\n",
      "Accuracy at step 930: 0.773438\n",
      "Accuracy at step 940: 0.773438\n",
      "Accuracy at step 950: 0.773438\n",
      "Accuracy at step 960: 0.773438\n",
      "Accuracy at step 970: 0.773438\n",
      "Accuracy at step 980: 0.773438\n",
      "Accuracy at step 990: 0.773438\n",
      "Accuracy at step 1000: 0.773438\n",
      "Accuracy at step 1010: 0.773438\n",
      "Accuracy at step 1020: 0.773438\n",
      "Accuracy at step 1030: 0.773438\n",
      "Accuracy at step 1040: 0.773438\n",
      "Accuracy at step 1050: 0.773438\n",
      "Accuracy at step 1060: 0.773438\n",
      "Accuracy at step 1070: 0.773438\n",
      "Accuracy at step 1080: 0.773438\n",
      "Accuracy at step 1090: 0.773438\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b48e0e0af08b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgen_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-30267895ee26>\u001b[0m in \u001b[0;36mgen_image\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m11\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmerged_summaries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m                     \u001b[0msummary_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m                     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;33m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m`\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdoesn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mexist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \"\"\"\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpartial_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 511\u001b[1;33m                            feed_dict_string)\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 564\u001b[1;33m                            target_list)\n\u001b[0m\u001b[0;32m    565\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    569\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m       \u001b[0me_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_traceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gen_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
