{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "from cStringIO import StringIO\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import shutil\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "sys.path.append(os.path.abspath(\"./slim/\"))\n",
    "import slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "def randfloat(a, b):\n",
    "    return rand.random() * (b - a) + a\n",
    "\n",
    "def my_print(s):\n",
    "    sys.stdout.write(s)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Directories and constants\n",
    "\n",
    "data_dir = \"./data/arrows/input_col/\"\n",
    "save_dir = \"./save_small/\"\n",
    "save_file_path = os.path.join(save_dir, \"model.ckpt\")\n",
    "logs_dir = \"./logs_small/\"\n",
    "\n",
    "create_dir(save_dir)\n",
    "create_dir(logs_dir)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parsing images\n",
    "\n",
    "def _create_fname_producers():\n",
    "    lines = os.listdir(data_dir)    \n",
    "    cnt = len(lines)\n",
    "    p = 0.9\n",
    "    train_cnt = int(cnt * p)\n",
    "    my_print(\"Total: %i images, train: %i\\n\" % (cnt, train_cnt))\n",
    "    train_lines = lines[:train_cnt]\n",
    "    test_lines = lines[train_cnt:]\n",
    "    return tf.train.string_input_producer(train_lines), tf.train.string_input_producer(test_lines)\n",
    "\n",
    "def _read_image(fname):\n",
    "    with tf.name_scope(\"read_image\"):\n",
    "        file_content = tf.read_file(tf.constant(data_dir) + fname)\n",
    "        image3c = tf.cast(tf.image.decode_png(file_content, channels=3, dtype=tf.uint8), tf.float32)\n",
    "        image1, image2 = tf.split(1, 2, image3c)\n",
    "        image1.set_shape((IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "        image2.set_shape((IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    return image1, image2\n",
    "\n",
    "def _generate_batch(image1, image2, batch_size, min_after_dequeue):\n",
    "    with tf.name_scope(\"generate_batch\"):\n",
    "        images1, images2 = tf.train.shuffle_batch([image1, image2], batch_size=batch_size / 2, \n",
    "                                                capacity=min_after_dequeue + batch_size * 4, \n",
    "                                                min_after_dequeue=min_after_dequeue,\n",
    "                                                num_threads=5)\n",
    "\n",
    "        images12 = tf.concat(0, [images1, images2])\n",
    "        images21 = tf.concat(0, [images2, images1])\n",
    "        labels12 = tf.concat(0, [tf.constant(1, tf.int64, [batch_size / 2]), \n",
    "                                 tf.constant(0, tf.int64, [batch_size / 2])])\n",
    "    return images12, images21, labels12\n",
    "\n",
    "def _producer_to_batch(queue, BATCH_SIZE, min_after_dequeue=5000):\n",
    "    image1, image2 = _read_image(queue.dequeue())\n",
    "    images1, images2, labels = _generate_batch(image1, image2, BATCH_SIZE,\n",
    "                                               min_after_dequeue=min_after_dequeue)\n",
    "    return images1, images2, labels\n",
    "    \n",
    "def get_data_batch(dual=True):\n",
    "    train_queue, test_queue = _create_fname_producers()\n",
    "    return _producer_to_batch(train_queue, BATCH_SIZE) + \\\n",
    "           _producer_to_batch(test_queue, BATCH_SIZE, BATCH_SIZE)\n",
    "\n",
    "def dense_to_one_hot(label_batch, num_labels=2):\n",
    "    with tf.name_scope(\"one_hot_encoder\"):\n",
    "        sparse_labels = tf.cast(tf.reshape(label_batch, [-1, 1]), tf.int32)\n",
    "        derived_size = tf.shape(sparse_labels)[0]\n",
    "        indices = tf.reshape(tf.range(0, derived_size, 1), [-1, 1])\n",
    "        concated = tf.concat(1, [indices, sparse_labels])\n",
    "        outshape = tf.concat(0, [tf.reshape(derived_size, [1]), tf.reshape(num_labels, [1])])\n",
    "        labels = tf.sparse_to_dense(concated, outshape, 1.0, 0.0)\n",
    "        labels = tf.cast(labels, tf.float32)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building network\n",
    "\n",
    "def normalize_images(images1, images2):\n",
    "    sz = tf.cast(tf.size(images1), tf.float32)\n",
    "    mean1 = tf.reduce_mean(images1, [1, 2, 3], True)\n",
    "#     sd1 = tf.sqrt(tf.reduce_sum(tf.square(images1 - mean1), [1, 2, 3], True) / sz)\n",
    "    mean1 = tf.tile(mean1, tf.shape(images1))\n",
    "#     return (images1 - mean1) / sd1, (images2 - mean1) / sd1\n",
    "    return (images1 - mean1), (images2 - mean1)\n",
    "\n",
    "def build_classifier(images1, images2, trainable=True):\n",
    "    images1, images2 = normalize_images(images1, images2)\n",
    "    images = tf.concat(3, [images1, images2])\n",
    "    \n",
    "    wd = 0.000005\n",
    "\n",
    "    with slim.arg_scope([slim.ops.conv2d], stddev=0.01, weight_decay=wd, trainable=trainable):\n",
    "        net = slim.ops.repeat_op(1, images, slim.ops.conv2d, 16, [3, 3], scope='conv1')\n",
    "        net = slim.ops.max_pool(net, [2, 2], scope='pool1')\n",
    "        net = tf.nn.lrn(net, name='lrn1')\n",
    "        net = slim.ops.repeat_op(1, net, slim.ops.conv2d, 32, [3, 3], scope='conv2')\n",
    "        net = slim.ops.max_pool(net, [2, 2], scope='pool2')\n",
    "        net = tf.nn.lrn(net, name='lrn2')\n",
    "        net = slim.ops.repeat_op(1, net, slim.ops.conv2d, 32, [3, 3], scope='conv3')\n",
    "        net = slim.ops.max_pool(net, [2, 2], scope='pool3')\n",
    "        net = tf.nn.lrn(net, name='lrn3')\n",
    "        net = slim.ops.repeat_op(1, net, slim.ops.conv2d, 32, [3, 3], scope='conv4')\n",
    "        net = slim.ops.max_pool(net, [2, 2], scope='pool4')\n",
    "        net = tf.nn.lrn(net, name='lrn4')\n",
    "        net = slim.ops.repeat_op(1, net, slim.ops.conv2d, 2, [3, 3], activation=None, scope='conv5')\n",
    "        \n",
    "        net = tf.reduce_mean(net, reduction_indices=[1, 2], name=\"reduce\")\n",
    "        net = tf.nn.softmax(net, name=\"softmax\")\n",
    "        \n",
    "    return net\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handling loss operations\n",
    "\n",
    "def build_loss(logits, labels):\n",
    "    with tf.name_scope(\"cross_entropy\"):\n",
    "        labels = tf.cast(labels, tf.int64)\n",
    "        dense_labels = dense_to_one_hot(labels)\n",
    "        clipped_logits = tf.clip_by_value(logits, 1e-10, 100.0)\n",
    "        cross_entropy = -dense_labels * tf.log(clipped_logits)\n",
    "        cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "        tf.add_to_collection(slim.losses.LOSSES_COLLECTION, cross_entropy_mean)\n",
    "\n",
    "    return cross_entropy_mean\n",
    "\n",
    "def get_total_loss(losses_list):\n",
    "    total_loss = tf.add_n(losses_list, name='total_loss')\n",
    "    loss_summary = _add_loss_summaries(losses_list + [total_loss])\n",
    "    return total_loss, loss_summary\n",
    "\n",
    "def _add_loss_summaries(losses_list):\n",
    "    loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')\n",
    "    loss_averages_op = loss_averages.apply(losses_list)\n",
    "    for l in losses_list:\n",
    "        tf.scalar_summary(l.op.name + '/raw', l)\n",
    "        tf.scalar_summary(l.op.name + '/avg', loss_averages.average(l))\n",
    "\n",
    "    return loss_averages_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building train operation\n",
    "\n",
    "def build_train(loss_op, step, init_rate=0.01, decay_steps=6000):\n",
    "    \n",
    "    with tf.name_scope(\"train\"):\n",
    "        optimizer = tf.train.AdamOptimizer(init_rate)\n",
    "        grads = optimizer.compute_gradients(loss_op)\n",
    "\n",
    "        apply_gradient_op = optimizer.apply_gradients(grads, global_step=step)\n",
    "\n",
    "        for var in tf.trainable_variables():\n",
    "            tf.histogram_summary(var.op.name, var)\n",
    "\n",
    "        for grad, var in grads:\n",
    "            if grad is not None:\n",
    "                tf.histogram_summary(var.op.name + '/gradients', grad)\n",
    "\n",
    "    return apply_gradient_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading & Saving session\n",
    "\n",
    "def load(saver, sess, to_print=True):\n",
    "    saver.restore(sess, save_file_path)\n",
    "    if to_print:\n",
    "        my_print(\"Model restored.\\n\")\n",
    "    \n",
    "def save(saver, sess):\n",
    "    save_path = saver.save(sess, save_file_path)\n",
    "    my_print(\"Model saved in file: %s\\n\" % save_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(prediction, labels_sparse):\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), labels_sparse)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    accuracy_summary = tf.scalar_summary(\"accuracy\", accuracy)\n",
    "    \n",
    "    return accuracy, accuracy_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_input_placeholders(image_size):\n",
    "    images1_ph = tf.placeholder(tf.float32, [None] + image_size, \"images1\")\n",
    "    images2_ph = tf.placeholder(tf.float32, [None] + image_size, \"images2\")\n",
    "    labels_ph = tf.placeholder(tf.int64, [None], \"labels\")\n",
    "    return images1_ph, images2_ph, labels_ph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training network\n",
    "\n",
    "def train_classifier(need_load, N=10000, init_rate=0.01):\n",
    "    \n",
    "    with tf.Graph().as_default() as g: \n",
    "        \n",
    "        step = slim.variables.variable('step', [], tf.int32, tf.constant_initializer(0), trainable=False)\n",
    "    \n",
    "        images1_train, images2_train, labels_train, images1_test, images2_test, labels_test = get_data_batch()\n",
    "        \n",
    "        images1_ph, images2_ph, labels_ph = create_input_placeholders([None, None, 3])\n",
    "        net_op = build_classifier(images1_ph, images2_ph, trainable=True)\n",
    "        \n",
    "        main_loss = build_loss(net_op, labels_ph)\n",
    "        total_loss, loss_summary = get_total_loss(tf.get_collection(slim.losses.LOSSES_COLLECTION))\n",
    "        \n",
    "        with tf.control_dependencies([loss_summary]):\n",
    "            train_op = build_train(total_loss, step, init_rate=init_rate)\n",
    "            \n",
    "        accuracy, accuracy_summary = calc_accuracy(net_op, labels_ph)\n",
    "\n",
    "        merged_summaries = tf.merge_all_summaries()\n",
    "\n",
    "        init = tf.initialize_all_variables()\n",
    "\n",
    "        sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "        saver = tf.train.Saver(var_list=tf.get_collection(slim.variables.VARIABLES_TO_RESTORE))\n",
    "        coord = tf.train.Coordinator()\n",
    "        writer = tf.train.SummaryWriter(logs_dir, sess.graph_def, flush_secs=30)\n",
    "\n",
    "        sess.run(init)\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "        try:\n",
    "\n",
    "            if need_load:\n",
    "                load(saver, sess)\n",
    "\n",
    "            my_print(\"Starting...\\n\")\n",
    "\n",
    "            for i in xrange(0, N):\n",
    "                if i % 11 == 0:\n",
    "                    im1, im2, lab = sess.run([images1_test, images2_test, labels_test])\n",
    "                    feed = {\n",
    "                        images1_ph : im1,\n",
    "                        images2_ph : im2,\n",
    "                        labels_ph : lab\n",
    "                    }\n",
    "                    result = sess.run([merged_summaries, accuracy, step], feed_dict=feed)\n",
    "                    summary_str = result[0]\n",
    "                    acc = result[1]\n",
    "                    st = result[2]\n",
    "#                     writer.add_summary(summary_str, st)\n",
    "                    print(\"Accuracy on test at step %s: %s\" % (st, acc))\n",
    "                else:\n",
    "                    im1, im2, lab = sess.run([images1_train, images2_train, labels_train])\n",
    "                    feed = {\n",
    "                        images1_ph : im1,\n",
    "                        images2_ph : im2,\n",
    "                        labels_ph : lab\n",
    "                    }\n",
    "                    result = sess.run([train_op, merged_summaries, accuracy, step], feed_dict=feed)\n",
    "                    summary_str = result[1]\n",
    "                    acc = result[2]\n",
    "                    st = result[3]\n",
    "                    if st % 10 == 0:\n",
    "                        writer.add_summary(summary_str, st)\n",
    "#                     print(\"Accuracy at step %s: %s\" % (st, acc))\n",
    "                    \n",
    "\n",
    "                if i % 100 == 0:\n",
    "                    save(saver, sess)\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_classifier(need_load=True, N=1000000, init_rate=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def showarray(a, name=None, fmt='png'):\n",
    "    a = np.uint8(np.clip(a, 0, 1)*255)[0]\n",
    "    if name is None:\n",
    "        f = StringIO()\n",
    "        PIL.Image.fromarray(a).save(f, fmt)\n",
    "        display(Image(data=f.getvalue()))\n",
    "    else:\n",
    "        PIL.Image.fromarray(a).save(name, fmt)\n",
    "    \n",
    "def visstd(a, s=0.1):\n",
    "    '''Normalize the image range for visualization'''\n",
    "    return (a-a.mean())/max(a.std(), 1e-4)*s + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_graph():\n",
    "        \n",
    "    images1_ph, images2_ph, labels_ph = create_input_placeholders([IMAGE_SIZE, IMAGE_SIZE, 3])\n",
    "    net_op = build_classifier(images1_ph, images2_ph, trainable=True)\n",
    "\n",
    "    init = tf.initialize_all_variables()\n",
    "\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "    saver = tf.train.Saver(var_list=tf.get_collection(slim.variables.VARIABLES_TO_RESTORE))\n",
    "\n",
    "    sess.run(init)\n",
    "    load(saver, sess, to_print=False)\n",
    "    \n",
    "    def maximize_output(layer_name, channel, iter_n=20, step=1.0, folder=None, seed=None):\n",
    "\n",
    "        t_obj = tf.get_default_graph().get_tensor_by_name(layer_name + ':0')[:, :, :, channel]\n",
    "        t_score = tf.reduce_mean(t_obj)\n",
    "        t_grad = tf.gradients(t_score, [images1_ph, images2_ph])\n",
    "\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        img1 = np.random.uniform(64, 192, size=(1, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "        img2 = img1.copy()\n",
    "\n",
    "        for i in xrange(iter_n):\n",
    "            g1, g2, score = sess.run([t_grad[0], t_grad[1], t_score], {images1_ph: img1, images2_ph: img2})\n",
    "            div = (np.concatenate((g1, g2))).std() + 1e-8\n",
    "            g1 /= div      \n",
    "            g2 /= div\n",
    "            img1 += g1 * step\n",
    "            img2 += g2 * step\n",
    "        if folder is None:\n",
    "            showarray(visstd(np.concatenate((img1, img2), 2)))\n",
    "        else:\n",
    "            showarray(visstd(np.concatenate((img1, img2), 2)), '%s%d.png' % (folder, channel))\n",
    "            \n",
    "    return maximize_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# maximize_output = prepare_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cnts = [48, 64, 128, 128]\n",
    "# for i in xrange(4):\n",
    "#     print i\n",
    "#     folder = 'images/%d/' % i\n",
    "#     create_dir(folder)\n",
    "#     for j in xrange(cnts[i]):\n",
    "#         maximize_output('conv%i/Conv/Relu' % (i + 1), j, 100, 10, folder=folder, seed=123)\n",
    "#     clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# maximize_output('conv3/Conv/Relu', 31, 100, 10, seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miltiscale generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tffunc(*argtypes):\n",
    "    '''Helper that transforms TF-graph generating function into a regular one.\n",
    "    See \"resize\" function below.\n",
    "    '''\n",
    "    placeholders = map(tf.placeholder, argtypes)\n",
    "    def wrap(f):\n",
    "        out = f(*placeholders)\n",
    "        def wrapper(*args, **kw):\n",
    "            return out.eval(dict(zip(placeholders, args)), session=kw.get('session'))\n",
    "        return wrapper\n",
    "    return wrap\n",
    "\n",
    "# Helper function that uses TF to resize an image\n",
    "def resize(img, size):\n",
    "#     img = tf.expand_dims(img, 0)\n",
    "    return tf.image.resize_bilinear(img, size)#[0, :, :, :]\n",
    "resize = tffunc(np.float32, np.int32)(resize)\n",
    "\n",
    "\n",
    "def calc_grad_tiled(sess, img1, img2, t_grad, images1_ph, images2_ph, tile_size=128):\n",
    "    '''Compute the value of tensor t_grad over the image in a tiled way.\n",
    "    Random shifts are applied to the image to blur tile boundaries over \n",
    "    multiple iterations.'''\n",
    "    sz = tile_size\n",
    "    h, w = img1.shape[1:3]\n",
    "    sx, sy = np.random.randint(sz, size=2)\n",
    "    img1_shift = np.roll(np.roll(img1, sx, 2), sy, 1)\n",
    "    img2_shift = np.roll(np.roll(img2, sx, 2), sy, 1)\n",
    "    grad1 = np.zeros_like(img1)\n",
    "    grad2 = np.zeros_like(img2)\n",
    "    for y in xrange(0, max(h - sz // 2, sz), sz):\n",
    "        for x in xrange(0, max(w - sz // 2, sz), sz):\n",
    "            sub1 = img1_shift[:, y : y + sz, x : x + sz]\n",
    "            sub2 = img2_shift[:, y : y + sz, x : x + sz]\n",
    "            g1, g2 = sess.run(t_grad, {images1_ph: sub1, images2_ph: sub2})\n",
    "            grad1[:, y : y + sz, x : x + sz] = g1\n",
    "            grad2[:, y : y + sz, x : x + sz] = g2\n",
    "    return np.roll(np.roll(grad1, -sx, 2), -sy, 1), np.roll(np.roll(grad2, -sx, 2), -sy, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_graph_multi():\n",
    "        \n",
    "    images1_ph, images2_ph, labels_ph = create_input_placeholders([None, None, 3])\n",
    "    net_op = build_classifier(images1_ph, images2_ph, trainable=True)\n",
    "\n",
    "    init = tf.initialize_all_variables()\n",
    "\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "    saver = tf.train.Saver(var_list=tf.get_collection(slim.variables.VARIABLES_TO_RESTORE))\n",
    "\n",
    "    sess.run(init)\n",
    "    load(saver, sess, to_print=False)\n",
    "    \n",
    "    def maximize_output(layer_name, channel, octave_n=3, octave_scale=2, iter_n=20, step=1.0, folder=None, seed=None):\n",
    "\n",
    "        t_obj = tf.get_default_graph().get_tensor_by_name(layer_name + ':0')[:, :, :, channel]\n",
    "        t_score = tf.reduce_mean(t_obj)\n",
    "        t_grad = tf.gradients(t_score, [images1_ph, images2_ph])\n",
    "\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        img1 = np.random.uniform(64, 192, size=(1, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "        img2 = img1.copy()\n",
    "        \n",
    "        for octave in xrange(octave_n):\n",
    "            print layer_name, channel, octave, \n",
    "            if octave > 0:\n",
    "                hw = np.float32(img1.shape[1:3]) * octave_scale\n",
    "                with sess.as_default():\n",
    "                    img1 = resize(img1, np.int32(hw))\n",
    "                    img2 = resize(img2, np.int32(hw))\n",
    "            for i in xrange(iter_n):\n",
    "                g1, g2 = calc_grad_tiled(sess, img1, img2, t_grad, images1_ph, images2_ph)\n",
    "                div = np.concatenate((g1, g2)).std() + 1e-8\n",
    "                g1 /= div\n",
    "                g2 /= div\n",
    "                img1 += g1 * step\n",
    "                img2 += g2 * step\n",
    "                print '.',\n",
    "            clear_output()\n",
    "            showarray(visstd(np.concatenate((img1, img2), 2)))\n",
    "        clear_output()\n",
    "        if folder is None:\n",
    "            showarray(visstd(np.concatenate((img1, img2), 2)))\n",
    "        else:\n",
    "            showarray(visstd(np.concatenate((img1, img2), 2)), '%s%d.png' % (folder, channel))\n",
    "            \n",
    "#         for i in xrange(iter_n):\n",
    "#             g1, g2, score = sess.run([t_grad[0], t_grad[1], t_score], {images1_ph: img1, images2_ph: img2})\n",
    "#             div = (np.concatenate((g1, g2))).std() + 1e-8\n",
    "#             g1 /= div      \n",
    "#             g2 /= div\n",
    "#             img1 += g1 * step\n",
    "#             img2 += g2 * step\n",
    "#         if folder is None:\n",
    "#             showarray(visstd(np.concatenate((img1, img2), 2)))\n",
    "#         else:\n",
    "#             showarray(visstd(np.concatenate((img1, img2), 2)), '%s%d.png' % (folder, channel))\n",
    "            \n",
    "    return maximize_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maximize_output_multi = prepare_graph_multi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cnts = [48, 64, 128, 128]\n",
    "cnts = [16, 32, 32, 32]\n",
    "for i in xrange(4):\n",
    "    print i + 1\n",
    "    folder = 'images_hd_small/%d/' % (i + 1)\n",
    "    create_dir(folder)\n",
    "    for j in xrange(cnts[i]):\n",
    "        maximize_output_multi('conv%i/Conv/Relu' % (i + 1), j, octave_n=4, octave_scale=1.4, iter_n=50, step=10,\n",
    "                        folder=folder, seed=123)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "maximize_output_multi('conv5/Conv/BiasAdd', 0, octave_n=4, octave_scale=1.4, iter_n=400, step=10, seed=123, \n",
    "                      folder='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gen_logs_dir = \"./logs_col_gen/\"\n",
    "\n",
    "# def predict_image(fname, N=10000000, init_rate=0.001):\n",
    "    \n",
    "#     with tf.Graph().as_default() as g: \n",
    "        \n",
    "#         step = slim.variables.variable('step_pred', [], tf.int32, tf.constant_initializer(0), \n",
    "#                                             trainable=False, restore=False)\n",
    "        \n",
    "#         image = imread(data_dir + fname, 'RGB')[:, :IMAGE_SIZE, :]\n",
    "#         imsave('in.png', image)\n",
    "#         imshow(image)\n",
    "#         show()\n",
    "#         image = np.reshape(image, (1, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "#         image1 = tf.constant(image, tf.float32, name='image1')\n",
    "#         image2 = tf.Variable(image1, trainable=True, name='image2')\n",
    "# #         image2 = tf.Variable(tf.random_uniform([1, IMAGE_SIZE, IMAGE_SIZE, 3], 0, 255), \n",
    "# #                     trainable=True, name='image2')\n",
    "        \n",
    "#         tf.image_summary(\"image1\", image1)\n",
    "#         tf.image_summary(\"image2\", image2)\n",
    "    \n",
    "#         images12 = tf.concat(0, [image1, image2], 'images1')\n",
    "#         images21 = tf.concat(0, [image2, image1], 'images2')\n",
    "#         labels = tf.constant([1, 0], tf.int64, [2], \"labels\")\n",
    "        \n",
    "#         answer_op = build_classifier(images12, images21, trainable=False)\n",
    "    \n",
    "#         loss_op = build_loss(answer_op, labels)\n",
    "#         losses_list = [\n",
    "#             loss_op \n",
    "# #             , slim.losses.l2_loss(image1 - image2, weight=1e-7)\n",
    "#         ]\n",
    "#         total_loss = tf.add_n(losses_list, name='total_loss')\n",
    "#         loss_summaries = _add_loss_summaries(losses_list + [total_loss])\n",
    "    \n",
    "#         with tf.control_dependencies([loss_summaries]):\n",
    "#             train_op = build_train(total_loss, step, init_rate=init_rate)\n",
    "    \n",
    "#         correct_prediction = tf.equal(tf.argmax(answer_op, 1), labels)\n",
    "#         accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#         accuracy_summary = tf.scalar_summary(\"accuracy\", accuracy)\n",
    "\n",
    "#         merged_summaries = tf.merge_all_summaries()\n",
    "\n",
    "#         init = tf.initialize_all_variables()\n",
    "\n",
    "#         sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "#         saver = tf.train.Saver(var_list=tf.get_collection(slim.variables.VARIABLES_TO_RESTORE))\n",
    "#         coord = tf.train.Coordinator()\n",
    "#         writer = tf.train.SummaryWriter(gen_logs_dir, sess.graph_def, flush_secs=30)\n",
    "\n",
    "#         sess.run(init)\n",
    "\n",
    "\n",
    "#         load(saver, sess)\n",
    "\n",
    "#         my_print(\"Starting...\\n\")\n",
    "\n",
    "#         for i in xrange(0, N):\n",
    "#             result = sess.run([train_op, merged_summaries, accuracy, step, image2])\n",
    "#             summary_str = result[1]\n",
    "#             acc = result[2]\n",
    "#             st = result[3]\n",
    "#             img = result[4]\n",
    "#             writer.add_summary(summary_str, st)\n",
    "# #                     print(\"Accuracy at step %s: %s\" % (st, acc))\n",
    "\n",
    "\n",
    "#             if i % 1000 == 0:\n",
    "#                 print i\n",
    "#                 out = np.clip(img[0], 0, 255).astype(np.uint8)\n",
    "#                 imsave('out.png', out)\n",
    "# #                     save(saver, sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# predict_image(\"543.png\", init_rate=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
